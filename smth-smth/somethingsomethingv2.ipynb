{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the 20BN-something-something Dataset V2\n==================================================\n\n`Something-something-v2 <https://20bn.com/datasets/something-something>`_  is an action recognition dataset\nof realistic action videos, collected from YouTube. With 220,847 short trimmed videos\nfrom 174 action categories, it is one of the largest and most widely used dataset in the research\ncommunity for benchmarking state-of-the-art video action recognition models. This tutorial\nwill go through the steps of preparing this dataset for GluonCV.\n\n\nDownload\n--------\n\nPlease refer to the `official website <https://20bn.com/datasets/something-something>`_ to download the videos.\nThe video data is provided as one large TGZ archive, split into parts of 1 GB max (there are 20 parts). The total download size is 19.4 GB.\nThe archive contains webm-files using the VP9 codec. Files are numbered from 1 to 220847.\nPlease use the provided md5sum to check if your downloaded parts are complete.\n\n============================================== ======\nFilename                                        Size\n============================================== ======\n20bn-something-something-v2-00                  1 GB\n20bn-something-something-v2-01                  1 GB\n20bn-something-something-v2-02                  1 GB\n20bn-something-something-v2-03                  1 GB\n20bn-something-something-v2-04                  1 GB\n20bn-something-something-v2-05                  1 GB\n20bn-something-something-v2-06                  1 GB\n20bn-something-something-v2-07                  1 GB\n20bn-something-something-v2-08                  1 GB\n20bn-something-something-v2-09                  1 GB\n20bn-something-something-v2-10                  1 GB\n20bn-something-something-v2-11                  1 GB\n20bn-something-something-v2-12                  1 GB\n20bn-something-something-v2-13                  1 GB\n20bn-something-something-v2-14                  1 GB\n20bn-something-something-v2-15                  1 GB\n20bn-something-something-v2-16                  1 GB\n20bn-something-something-v2-17                  1 GB\n20bn-something-something-v2-18                  1 GB\n20bn-something-something-v2-19                 445 MB\n============================================== ======\n\nOnce confirmed, you can use the following command to unzip the videos.\n\n.. code-block:: bash\n\n   cat 20bn-something-something-v2-?? | tar zx\n\nSuppose by default the root directory for your data is ``ROOT=~/.mxnet/datasets/somethingsomethingv2``,\nall the videos will be stored at ``ROOT/20bn-something-something-v2`` now.\nThen, download the annotations and put them into folder ``ROOT/annotations``.\n\n============================================== ======\nFilename                                        Size\n============================================== ======\nsomething-something-v2-labels.json               9 KB\nsomething-something-v2-train.json               26 MB\nsomething-something-v2-validation.json         3.7 MB\nsomething-something-v2-test.json               448 KB\n============================================== ======\n\n\nPreprocess\n----------\n\nThe easiest way to prepare the dataset is to download helper script\n:download:`somethingsomethingv2.py<../../../scripts/datasets/somethingsomethingv2.py>` and run the following command:\n\n.. code-block:: bash\n\n   python somethingsomethingv2.py\n\nThis script will help you decode the videos to raw frames and generate training files for standard data loading.\nThe video frames will be saved at ``ROOT/20bn-something-something-v2-frames``. The training files will be\nsaved at ``ROOT/annotations``. The data preparation process may take a while. The total time to prepare\nthe dataset depends on your machine. For example, it takes about 6 hours on an AWS EC2 instance with EBS.\n\nOnce the script is done, you can start training your action recognition models on something-something-v2 dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
